{"cells":[{"cell_type":"code","source":["!pip install pyspark"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-taBf4FTlXeb","executionInfo":{"status":"ok","timestamp":1718265214833,"user_tz":-540,"elapsed":57644,"user":{"displayName":"이현우","userId":"14196527885119656821"}},"outputId":"cf17f5e1-654a-4571-bf58-05980bceb9a0"},"id":"-taBf4FTlXeb","execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pyspark\n","  Downloading pyspark-3.5.1.tar.gz (317.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.0/317.0 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n","Building wheels for collected packages: pyspark\n","  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyspark: filename=pyspark-3.5.1-py2.py3-none-any.whl size=317488491 sha256=7d07406a6f047de0f0d907b67cceb2157c0abd23b5f57bbe77f5a2b98bfe7130\n","  Stored in directory: /root/.cache/pip/wheels/80/1d/60/2c256ed38dddce2fdd93be545214a63e02fbd8d74fb0b7f3a6\n","Successfully built pyspark\n","Installing collected packages: pyspark\n","Successfully installed pyspark-3.5.1\n"]}]},{"cell_type":"code","execution_count":8,"id":"2b14b925-e672-436d-b70b-028813f0e459","metadata":{"id":"2b14b925-e672-436d-b70b-028813f0e459","executionInfo":{"status":"ok","timestamp":1718265475954,"user_tz":-540,"elapsed":350,"user":{"displayName":"이현우","userId":"14196527885119656821"}}},"outputs":[],"source":["import pyspark\n","from pyspark.sql import SparkSession\n","from pyspark.ml.regression import RandomForestRegressor\n","from pyspark.ml.evaluation import RegressionEvaluator\n","from pyspark.ml.feature import VectorAssembler\n","from pyspark.ml.tuning import CrossValidator, ParamGridBuilder"]},{"cell_type":"code","source":["spark = SparkSession.builder.appName(\"Insurance_RF\").getOrCreate()"],"metadata":{"id":"KTiruJfpmhJj","executionInfo":{"status":"ok","timestamp":1718265476261,"user_tz":-540,"elapsed":1,"user":{"displayName":"이현우","userId":"14196527885119656821"}}},"id":"KTiruJfpmhJj","execution_count":9,"outputs":[]},{"cell_type":"code","source":["df = spark.read.csv(\"insurance.csv\", header=True, inferSchema=True)"],"metadata":{"id":"8nz-uocimi-q","executionInfo":{"status":"ok","timestamp":1718265477950,"user_tz":-540,"elapsed":910,"user":{"displayName":"이현우","userId":"14196527885119656821"}}},"id":"8nz-uocimi-q","execution_count":10,"outputs":[]},{"cell_type":"markdown","id":"c4011f20-c59b-4e23-92de-4a373e5be495","metadata":{"id":"c4011f20-c59b-4e23-92de-4a373e5be495"},"source":["## <span style=\"line-height:1.7\">**insurance.csv**를 로드하여 <b><font color='blue'>Random forest regressor</font></b>을 생성하시오.</span>\n","> - **X**(feature)는 **age, sex, bmi, children** 4개의 column으로 하고, **charges**를 **y**로 한다.\n",">\n","> - **학습(train)** 데이터와 **테스트(test)** 데이터를 **6:4** 비율로 나눈다.\n",">  \n","> - 학습 데이터를 **3개 그룹**으로 분리하여 **cross validation**을 수행하되, <font color='blue'>**minInstancesPerNode**</font> parameter는 <font color='red'>**1**</font>, <font color='red'>**100**</font>, <font color='blue'>**featureSubsetStrategy**</font> parameter는 <font color='red'>**onethird**</font>, <font color='red'>**sqrt**</font>가 적용된 regressor 중 <font color='red'>**R2 score**</font>가 가장 높은 best model을 찾으시오. <br>(**best model의 minInstancesPerNode와 featureSubsetStrategy**를 찾으시오.)\n",">  \n","> - **best model**의 <font color='red'><b>training data</b>에 대한 <b>R2</b></font>, <font color='red'><b>test data</b>에 대한 <b>R2</b></font>를 찾으시오."]},{"cell_type":"code","source":["rf = RandomForestRegressor(featuresCol='features', labelCol='charges')\n","\n","cv = CrossValidator(estimator=rf,\n","                    estimatorParamMaps=ParamGridBuilder()\n","                    .addGrid(rf.minInstancesPerNode, [1, 100])\n","                    .addGrid(rf.featureSubsetStrategy, ['onethird', 'sqrt'])\n","                    .build(),\n","                    evaluator=RegressionEvaluator(labelCol='charges'),\n","                    numFolds=3)\n","\n","cvModel = cv.fit(train)\n","\n","best_model = cvModel.bestModel\n","\n","train_predictions = best_model.transform(train)\n","test_predictions = best_model.transform(test)\n","\n","evaluator = RegressionEvaluator(labelCol='charges', predictionCol='prediction', metricName='r2')\n","train_r2 = evaluator.evaluate(train_predictions)\n","test_r2 = evaluator.evaluate(test_predictions)\n","\n","print('Best model parameters:')\n","print(f'minInstancesPerNode: {best_model.getMinInstancesPerNode()}')\n","print(f'featureSubsetStrategy: {best_model.getFeatureSubsetStrategy()}')\n","print('Training R2:', train_r2)\n","print('Test R2:', test_r2)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4OKPwxTWpRsD","executionInfo":{"status":"ok","timestamp":1718266215861,"user_tz":-540,"elapsed":18186,"user":{"displayName":"이현우","userId":"14196527885119656821"}},"outputId":"4accf324-4a12-477f-e33c-79c7300ec43f"},"id":"4OKPwxTWpRsD","execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["Best model parameters:\n","minInstancesPerNode: 100\n","featureSubsetStrategy: onethird\n","Training R2: 0.13071607145491482\n","Test R2: 0.10732446373910398\n"]}]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.8"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}